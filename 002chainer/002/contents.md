# Chainerの基本：backward

Variableオブジェクトは値だけではなく，それまでの計算履歴を全て持っています。
この計算履歴にはどのような変数と変数をどのような演算で組み合わせたかという情報を全て持っています。

## メモ

この計算履歴はdump_graphを使って図示化することができます。使い方は[mnist example](https://github.com/pfnet/chainer/blob/master/examples/mnist/train_mnist.py)を参照してください。

この計算履歴の情報を使って，最終的な値に対する各変数についての勾配（gradient, grad）を計算することができます。

Chainerでは勾配を逆誤差伝播法を使って効率的に求めることができます。

さきほどの演算結果であるVaribleオブジェクトyのbackward関数を呼び出すことで自動的に勾配を計算し途中のVaribleのgrad属性に勾配を設定します

```
y.backward()
print x.grad
```

値yの変数xについての勾配というのは，簡単に言えばxをほんの少しだけ増やした時，yがどの程度変わるのかという値です。

例えば，y=2xというのは，xをほんの少しdだけ増やした時，2dだけ増えます。
そのためy=2xのxについての勾配は（xによらず）2となります。

xがベクトルやテンソルの場合には，各要素について，他の要素を固定した上で，対象の要素だけを少しだけ動かした時にどの程度変わるのかという値になります。これは数学的には偏微分とよびます。

変数xがベクトルやテンソルの場合は勾配はその要素毎の偏微分を並べたベクトルやテンソルになります。
このため勾配ベクトルとよんだりもします。

また，勾配ベクトルは今の各変数をどの方向に動かしたら最も急激に関数が大きくなるのかという値を意味しています。
ちなみに勾配ベクトルの逆向きは最も急激に関数の値を小さくなる方向です。

## 課題

右の例，実際に求めた勾配を0.01倍したものをxに足した上でyの値が実際に大きくなっていることを確かめよ


