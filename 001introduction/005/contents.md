# 2. 目的関数を定義する

次に目的関数を定義します。

目的関数は何を学習させたいのかを表す関数です。
目的関数は一つの値を出力し，値が小さければ望ましい状態を表すような関数です。

ここでは，代表的な学習問題である分類教師あり学習の目的関数を例に考えます。
分類とは入力 $x$ から出力 $y \in \\{ 1, ..., k \\}$ を推定する問題です。出力はラベルと呼ばれます。
例えば，画像からそこに写っている動物を推定したい場合では，入力 $x$ が画像であり，出力 $y$ がそのラベル（猫，犬など）となります。

この学習を行うためには，入力と正解の出力のペアからなる $n$ 個の学習データ

$$D = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}$$

を与えます。そして，このデータを使って入力から出力を推定したときにどのような目的関数を用意すればいいのかを考えます。
今回，学習したいのは $x$ が与えられた時に $y$ の条件付き確率 $p(y \mid x)$ を出力してくれるようなモデルです。
このようなカテゴリ値（離散値）に対する確率分布をモデル化するにはSoftmaxを利用します。

## Softmax

Softmax（または多クラスロジスティックスモデル）とは $d$ 次元の実数値ベクトルから，
$d$ 次元の確率分布を作る方法の一つです。

$softmax(x)$ は，$x$ が $d$ 次元であり，各次元の値が $x[0], x[1], ..., x[d-1]$ の時，

$$y[i]=\frac{\exp(x[i])}{\sum_i \exp(x[i])}$$

と表されます。

あるベクトルvが確率分布となる条件として，

1. 各次元の値が非負
2. 合計値が1

という条件があります。
Softmaxは， $\exp$ が非負であることから1の条件を満たし，各次元の値を足した値で割っていることから2の条件を満たします。

Chainerでは `chainer.functions` で `softmax` 関数が定義されているのでそれを利用できます。

```
y = F.softmax(x)
```

## 目的関数

今回の分類は $x$ が与えられた時の $y$ の条件付き確率 $p(y \mid x)$ の推定問題する問題となります。

先ほど，任意のベクトル $v$ は関数 $softmax$ を適用するとその出力は確率分布となることを学びました。

$$y = softmax(f(x; \theta))$$

この学習対象のモデルを簡単に $q(y \mid x; \theta)$ と書くことにします。

学習の目標は学習データの確率分布 $p(y|x)$ と，学習対象のモデルによる確率分布 $q(y \mid x; \theta)$ が一致するようにすることです。
確率分布間がどれだけ離れているかを表す指標としてKLダイバージェンスが知られています。
KLダイバージェンスは二つの確率分布 $P$ と $Q$ の遠さを次のように定義します。

```math
\begin{align}
KL(P \mid\mid Q) &= \sum_x P(x) \log \frac{P(x)}{Q(x)} \\
                 &= \sum_x P(x) \log P(x) - \sum_x P(x) \log Q(x)
\end{align}
```

もし， $P$ と $Q$ が同じならば，全ての $x$ について $\frac{P(x)}{Q(x)}=1$ となるので $KL(P \mid\mid Q)=0$ となります。
この二つの分布が違うと， $KL(P \mid\mid Q)>0$ となり，近ければ近いほど0に近づくような指標です。

学習データによって定義される確率分布は訓練分布と呼ばれ，それに基づく条件付き確率は

```math
\begin{align}
P(y \mid x) &= \frac{P(x, y)}{P(x)} \\
            &= \frac{1}{n} \sum_{i} \frac{I(x=x_i, y=y_i)}{I(x=x_i)}
\end{align}
```

と表されます。
但し， $I$ はデルタ関数とよばれ， $I(c)$ は $c$ が真である時は $\infty$，それ以外は $0$ であるような関数です。


訓練分布に基づく条件づき確率 $P(y \mid x)$ と，モデルによる条件づき確率 $Q(y \mid x)$ のKLダイバージェンスは

```math
\begin{align}
KL(P \mid\mid Q) &= \sum_{x} \sum_y P(y \mid x) \log \frac{P(y \mid x)}{Q(y \mid x)} \\
                 &= \sum_{x, y} P(y \mid x) \log P(y \mid x) - \sum_{x, y} P(y \mid x) \log Q(y \mid x)
\end{align}
```

となります。
この最適化において， $Q$ に依存する項は第二項のみであり， $(x, y) \in D$ の時 $P(y \mid x)=1$ ，それ以外 $0$ ですので

$L(\theta) = - \sum_{i=1}^n \log Q(y_i \mid x_i)$

となります。
これをクロスエントロピー損失関数，または負の対数尤度ともよばれます。

ここまで読んだ方で，なぜ学習データ $D$ から得られた確率分布 $P$ そのものを直接使わず，学習モデルによる確率 $Q$ を使うのかと思った方がいるかもしれません。
それは，学習の目標は学習データだけをうまく分類することではなく未知のデータをうまく分類することだからです。

$P$ は，入力が学習データと全く同じであればそれが正解となりますが，そうでない場合は確率分布が不定になりえます。
$Q$ はありえそうなモデルの中で一番 $P$ に近い分布を探しています。
$Q$ は $P$ とは違って全ての $x$ について確率分布を与えることができるため，学習データには含まれない未知のデータでもうまく分類できます。
別の言い方をするとPを平滑化した確率分布がQとなります。

得られた目的関数 $L(\theta)$ は学習対象のモデルのパラメータ $\theta$
によって値が決まる関数であることに注意してください。
この目的関数は，学習データをうまく分類できるような確率分布に対応するパラメータであれば小さい値をとり，そうでない場合は大きな値をとるような関数です。

これにより，学習という問題を目的関数を最小化する最適化問題に変換することができました。

ChainerではSoftmaxを適用した後に，クロスエントロピー損失関数を適用した目的関数が用意されています。
これは，二つまとめて処理をしないと，数値誤差の問題があるためです。

```
# x は入力, tは正解の出力
h = MLP(x)
loss = F.softmax_cross_entropy(h, t)
```

この目的関数をどのように小さくするかは次章で扱います。

また，推定する値が連続値のである回帰問題の場合は次の二乗誤差を使います

$$\\|y - f(x)\\|^2$$

これは，Chainerでは `mean_squared_error` として用意されています。

```
loss = F.mean_squared_error(h, t)
```

損失関数のいくつは `chainer.functions` 内で定義されています。
また，自分で新しい損失関数を定義することもできます。
