# 2. 目的関数を定義する

次に目的関数を定義します。

目的関数は何を学習させたいのかを表す関数です。
目的関数は一つの値を出力し，値が小さければ望ましい状態を表すような関数です。

ここでは，代表的な学習問題である分類教師あり学習の目的関数を例に考えます。
分類とは入力 $x$ から出力 $y \in \{1, ..., k\}$ を推定する問題です。出力はラベルと呼ばれます。
例えば，画像からそこに写っている動物を推定したい場合では，入力 $x$ が画像であり，出力 $y$ がそのラベル（猫，犬など）となります。

この学習を行うためには，入力と正解の出力のペアからなる $n$ 個の訓練データ

$$D = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}$$

を与えます。そして，このデータを使って入力から出力を推定したときにどのような目的関数を用意すればいいのかを考えます。

## Softmax

目的関数を考える前に，まずSoftmaxについて説明します。
Softmax（または他クラスロジスティックスモデル）とは $d$ 次元の実数値ベクトルから，
$d$ 次元の確率分布を作る方法の一つです。

$softmax(x)$ は，$x$ が $d$ 次元であり，各次元の値が $x[0], x[1], ..., x[d-1]$ の時，

$$y[i]=exp(x[i])/\sum_i exp(x[i])$$

と表されます。

あるベクトルvが確率分布となる条件として，

1. 各次元の値が非負
2. 合計値が1

という条件があります。
Softmaxは， $exp$ が非負であることから1の条件を満たし，各次元の値を足した値で割っていることから2の条件を満たします。

Chainerでは `chainer.functions` で `softmax` 関数が定義されているのでそれを利用できます。

```
y = F.softmax(x)
```

## 目的関数

今回の分類は $x$ が与えられた時の $y$ の条件付き確率 $p(y|x)$ の推定問題する問題となります。

先ほど，任意のベクトル $v$ は関数 $softmax$ を適用するとその出力は確率分布となることを学びました。

$$y = softmax(f(x; \theta))$$

この学習対象のモデルを簡単に $q(y|x; \theta)$ と書くことにします。

学習の目標は訓練データの確率分布 $p(y|x)$ と，学習対象の確率分布 $q(y|x; \theta)$ が一致するようにすることです。
確率分布間がどれだけ離れているかを表す指標としてKLダイバージェンスが知られています。
KLダイバージェンスは二つの確率分布 $P$ と $Q$ の遠さを次のように定義します。

```math
KL(P||Q) = \sum_x P(x) log P(x) / Q(x) \\
         = \sum_x P(x) log P(x) - \sum_x P(x) log Q(x)
```

もし， $P$ と $Q$ が同じならば，全ての $x$ について $P(x)/Q(x)=1$ となるので $KL(P||Q)=0$ となります。
この二つの分布が違うと， $KL(P||Q)>0$ となり，近ければ近いほど0に近づくような指標です。

訓練データによって定義される確率分布は訓練分布と呼ばれ，それに基づく条件付き確率は

```math
P(y|x) = P(x, y) / P(x) \\
       = \frac{1}{n} \sum_{i} I(x=x_i, y=y_i) / \sum_i I(x=x_i)
```

と表されます。

訓練分布に基づく条件づき確率 $P(y|x)$ と，モデルによる条件づき確率 $Q(y|x)$ のKLダイバージェンスは

```math
KL(P||Q) = \sum_{x} \sum_y P(y|x) log P(y|x) / Q(y|x) \\
        = \sum_{x, y} P(y|x) log P(y\x) - \sum_{x, y} P(y|x) log Q(y|x)
```

となります。
この最適化において， $Q$ に依存する項は第二項のみであり， $(x, y) \in D$ の時 $P(y|x)=1$ ，それ以外 $0$ ですので

$L(\theta) = - \sum_{i=1}^n \log Q(y_i | x_i)$

となります。
これは負の対数尤度ともよばれます。

ここまで読んだ方で，なぜ訓練データ $D$ から得られた $P$ そのものを直接使わず， $P$ を推定した $Q$ を使うのかと思った方がいるかもしれません。

学習の目標は訓練データをうまく分類することではなく未知のデータをうまく分類することです。
$P$ は，入力が訓練データと全く同じであればそれが正解となりますが，そうでない場合は確率分布が不定です。
$Q$ はありえそうなモデルの中で一番 $P$ に近い分布を探しています。
$Q$ は $P$ とは違って全ての $x$ について確率分布を与えることができるため，みたことがない未知のデータでもうまく分類できます。

得られた目的関数 $L(\theta)$ は学習対象のモデルのパラメータ $\theta$
によって値が決まる関数であることに注意してください。
この目的関数は，訓練データをうまく分類できるような確率分布に対応するパラメータであれば小さい値をとり，そうでない場合は大きな値をとるような関数です。

これにより，学習という問題を目的関数を最小化する最適化問題に変換することができました。

ChainerではSotmaxを適用した後に，クロスエントロピー損失関数を適用した目的関数が用意されています。
これは，二つまとめて処理をしないと，数値誤差の問題があるためです。

```
loss = F.softmax_cross_entropy(h, t)
```

この目的関数をどのように小さくするかは次章で扱います。

また，推定する値が連続値のである回帰問題の場合は次の二乗誤差を使います

$$||y - f(x)||^2$$

```
loss = F.mean_squared_error(h, t)
```

損失関数のいくつは `chainer.functions` 内で定義されています。
また，自分で新しい損失関数を定義することもできます。
